{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlJZdJs3EI/8QuVbSRRaQB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guimaraesabrina/mastering_spaCy/blob/main/mastering_spacy_chapters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mastering spaCy\n",
        "## Chapter 1: Getting started with spaCy\n",
        "\n"
      ],
      "metadata": {
        "id": "8t8gXJ0St81X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install spaCy library and setup"
      ],
      "metadata": {
        "id": "a6vkBym-sdXW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWTTKi7SgEJ5"
      },
      "outputs": [],
      "source": [
        "%pip install -U spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "nbw-9kbVjz6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "from spacy import displacy"
      ],
      "metadata": {
        "id": "AR_uexWIjoYm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to load the model"
      ],
      "metadata": {
        "id": "UO0vPsxJsjYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "cm1O05c6jsft"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Hi! My name is Sabrina Guimarães. I live in São Paulo and I'm working at NTT DATA\")\n",
        "doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3bpkwPLkEg2",
        "outputId": "5fdf8541-4262-4731-f21a-619134d1847a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Hi! My name is Sabrina Guimarães. I live in São Paulo and I'm working at NTT DATA"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entity recognition"
      ],
      "metadata": {
        "id": "GS7Hg7lCspT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "displacy.serve(doc, style='ent')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "yGCWYBDhq3FG",
        "outputId": "1e179d37-9076-4943-f87b-b8a913effea9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
              "<html lang=\"en\">\n",
              "    <head>\n",
              "        <title>displaCy</title>\n",
              "    </head>\n",
              "\n",
              "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
              "<figure style=\"margin-bottom: 6rem\">\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Hi! My name is \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Sabrina Guimarães\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ". I live in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    São Paulo\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " and I'm working at \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    NTT DATA\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              "</div>\n",
              "</figure>\n",
              "</body>\n",
              "</html></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using the 'ent' visualizer\n",
            "Serving on http://0.0.0.0:5000 ...\n",
            "\n",
            "Shutting down server on port 5000.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter 2: Core operations with spaCy\n"
      ],
      "metadata": {
        "id": "SwvbgJFkuSFr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Tokenization\n",
        "- Lemmatization\n",
        "- POS Tagger (part-of-speech tagger)\n",
        "- Parser (Dependency Parser)"
      ],
      "metadata": {
        "id": "rLzFNfIcwA0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "id": "F-SDR5EEulzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_md\")"
      ],
      "metadata": {
        "id": "A-WJZjmRuYZX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"I went there\")"
      ],
      "metadata": {
        "id": "lsxXrivzu5Hz"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%python -m spacy download pt_core_news_sm"
      ],
      "metadata": {
        "id": "_D-gsMqVvaVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "text = \"Oi. Meu nome é Sabrina e eu tenho 3 gatos\"\n",
        "doc = nlp(text)\n",
        "\n",
        "print(\"Tokens:\")\n",
        "for token in doc:\n",
        "    print(token.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PIwe-McvVBs",
        "outputId": "c551980f-62f4-4b68-ea7a-93a472d27dbb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens:\n",
            "Oi\n",
            ".\n",
            "Meu\n",
            "nome\n",
            "é\n",
            "Sabrina\n",
            "e\n",
            "eu\n",
            "tenho\n",
            "3\n",
            "gatos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nLematização:\")\n",
        "for token in doc:\n",
        "    print(f\"Lema: {token.lemma_}\")\n",
        "\n",
        "    # ter\n",
        "    # ser\n",
        "    # base form of a token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74JI6jeewJBH",
        "outputId": "1ee728da-ee90-4f2d-9dfd-3167833f04ca"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Lematização:\n",
            "Lema: Oi\n",
            "Lema: .\n",
            "Lema: meu\n",
            "Lema: nome\n",
            "Lema: ser\n",
            "Lema: Sabrina\n",
            "Lema: e\n",
            "Lema: eu\n",
            "Lema: ter\n",
            "Lema: 3\n",
            "Lema: gato\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"A Maria corre rápido para pegar o ônibus e não se atrasar para a faculdade.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "print(\"\\nPOS Tagger:\")\n",
        "for token in doc:\n",
        "    print(f\"Token: {token.text}, POS (Universal): {token.pos_}, POS (Detalhada): {token.tag_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L81q6Nqfw3Lv",
        "outputId": "ec3241e2-ba4a-490b-e608-45fa2291c9fd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "POS Tagger:\n",
            "Token: A, POS (Universal): DET, POS (Detalhada): DET\n",
            "Token: Maria, POS (Universal): PROPN, POS (Detalhada): PROPN\n",
            "Token: corre, POS (Universal): VERB, POS (Detalhada): VERB\n",
            "Token: rápido, POS (Universal): ADV, POS (Detalhada): ADV\n",
            "Token: para, POS (Universal): SCONJ, POS (Detalhada): SCONJ\n",
            "Token: pegar, POS (Universal): VERB, POS (Detalhada): VERB\n",
            "Token: o, POS (Universal): DET, POS (Detalhada): DET\n",
            "Token: ônibus, POS (Universal): NOUN, POS (Detalhada): NOUN\n",
            "Token: e, POS (Universal): CCONJ, POS (Detalhada): CCONJ\n",
            "Token: não, POS (Universal): ADV, POS (Detalhada): ADV\n",
            "Token: se, POS (Universal): PRON, POS (Detalhada): PRON\n",
            "Token: atrasar, POS (Universal): VERB, POS (Detalhada): VERB\n",
            "Token: para, POS (Universal): ADP, POS (Detalhada): ADP\n",
            "Token: a, POS (Universal): DET, POS (Detalhada): DET\n",
            "Token: faculdade, POS (Universal): NOUN, POS (Detalhada): NOUN\n",
            "Token: ., POS (Universal): PUNCT, POS (Detalhada): PUNCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"O cachorro grande latiu alto na rua.\"\n",
        "doc = nlp(text)\n",
        "for token in doc:\n",
        "    print(f\"Token: {token.text}, Head: {token.head.text}, Relação: {token.dep_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4l0k7iCC3_B4",
        "outputId": "d61cef6e-147a-41f7-ad5f-c64b03e860a0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token: O, Head: cachorro, Relação: det\n",
            "Token: cachorro, Head: latiu, Relação: nsubj\n",
            "Token: grande, Head: cachorro, Relação: amod\n",
            "Token: latiu, Head: latiu, Relação: ROOT\n",
            "Token: alto, Head: latiu, Relação: advmod\n",
            "Token: na, Head: rua, Relação: case\n",
            "Token: rua, Head: latiu, Relação: obl\n",
            "Token: ., Head: latiu, Relação: punct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "displacy.render(doc, style=\"dep\", jupyter=True, options={\"distance\": 90})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "eI6vuRjI4QAV",
        "outputId": "da5dac0f-82ae-479f-ea5f-dc4b09dacbcd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"pt\" id=\"7249cc5f728044f7841df9267060db20-0\" class=\"displacy\" width=\"680\" height=\"227.0\" direction=\"ltr\" style=\"max-width: none; height: 227.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">O</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">cachorro</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">grande</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">latiu</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">alto</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">na</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">rua.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-7249cc5f728044f7841df9267060db20-0-0\" stroke-width=\"2px\" d=\"M70,92.0 C70,47.0 135.0,47.0 135.0,92.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-7249cc5f728044f7841df9267060db20-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,94.0 L62,82.0 78,82.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-7249cc5f728044f7841df9267060db20-0-1\" stroke-width=\"2px\" d=\"M160,92.0 C160,2.0 320.0,2.0 320.0,92.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-7249cc5f728044f7841df9267060db20-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M160,94.0 L152,82.0 168,82.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-7249cc5f728044f7841df9267060db20-0-2\" stroke-width=\"2px\" d=\"M160,92.0 C160,47.0 225.0,47.0 225.0,92.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-7249cc5f728044f7841df9267060db20-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M225.0,94.0 L233.0,82.0 217.0,82.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-7249cc5f728044f7841df9267060db20-0-3\" stroke-width=\"2px\" d=\"M340,92.0 C340,47.0 405.0,47.0 405.0,92.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-7249cc5f728044f7841df9267060db20-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M405.0,94.0 L413.0,82.0 397.0,82.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-7249cc5f728044f7841df9267060db20-0-4\" stroke-width=\"2px\" d=\"M520,92.0 C520,47.0 585.0,47.0 585.0,92.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-7249cc5f728044f7841df9267060db20-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M520,94.0 L512,82.0 528,82.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-7249cc5f728044f7841df9267060db20-0-5\" stroke-width=\"2px\" d=\"M340,92.0 C340,2.0 590.0,2.0 590.0,92.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-7249cc5f728044f7841df9267060db20-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M590.0,94.0 L598.0,82.0 582.0,82.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenization\n",
        "\n",
        "doc = nlp(\"It's been a crazy week!!!\")\n",
        "print([token.text for token in doc])\n",
        "\n",
        "# Tokenization does not need a specific model\n",
        "# Tokenization is based on language-specific-rules\n",
        "# Tokenization rules depends on the grammatical rules of the individual language"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kFc1aD985DS",
        "outputId": "ed2967af-b2d4-4bc7-b918-9a39185f88ee"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['It', \"'s\", 'been', 'a', 'crazy', 'week', '!', '!', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Costumizing the tokenizer"
      ],
      "metadata": {
        "id": "2i_aRAAk-TbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.symbols import ORTH"
      ],
      "metadata": {
        "id": "4DuejMqQ-YgK"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"lemme that\")\n",
        "print([w.text for w in doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WxaNdR1-fQL",
        "outputId": "32e53222-f784-4237-91b7-1e86b4abbd96"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['lemme', 'that']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "special_case = [{\"ORTH\":\"lem\"}, {\"ORTH\":\"me\"}]\n",
        "nlp.tokenizer.add_special_case(\"lemme\", special_case)\n",
        "print([w.text for w in nlp(\"lemme that\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VFXG5S2-u6f",
        "outputId": "7323b9df-65ce-4d9e-c515-c5b41b82079b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['lem', 'me', 'that']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentence segmentation"
      ],
      "metadata": {
        "id": "o626RNjt_qDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I flied to N.Y yesterday. It was around 9 am.\"\n",
        "doc = nlp(text)\n",
        "for sent in doc.sents:\n",
        "  print(sent.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cewx6i1XAMxx",
        "outputId": "d6a6dcdc-0f06-467c-b3e9-b433f973dc67"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I flied to N.Y yesterday.\n",
            "It was around 9 am.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lemma"
      ],
      "metadata": {
        "id": "cqUgPbVGFFuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.get_pipe(\"attribute_ruler\").add([[{\"TEXT\":\"Angeltown\"}]], {\"LEMMA\": \"Los Angeles\"})"
      ],
      "metadata": {
        "id": "JLu3cF17FJXU"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"I am flying to Angeltown\")\n",
        "for token in doc:\n",
        "  print (token.text, token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoBZdXjMFx8x",
        "outputId": "9f7fc2ab-8868-416d-e8dc-1e338da74622"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I I\n",
            "am be\n",
            "flying fly\n",
            "to to\n",
            "Angeltown Los Angeles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print the entities\n",
        "\n",
        "doc = nlp(\"I flied to NY with Ashley\")\n",
        "entities = doc.ents\n",
        "print(entities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oE19YgQ0GT69",
        "outputId": "37fe0752-1159-4420-b32d-5f99f705e95b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(NY, Ashley)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# each sentence is a Span object\n",
        "\n",
        "doc = nlp(\"This is the 1st sentence. This is the 2nd sentence. And blablabla.\")\n",
        "sentences = list(doc.sents)\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRxxajOQGluQ",
        "outputId": "98a1f117-21fb-41d9-b5a0-9ae9a6a6d09c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[This is the 1st sentence., This is the 2nd sentence., And blablabla.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Focus on token object"
      ],
      "metadata": {
        "id": "MwoLs9dMHss2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Hello madam!\")\n",
        "print(doc[0])\n",
        "print(doc[1])\n",
        "print(doc[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_wsMGFfHvfZ",
        "outputId": "1a090ff7-803f-4db9-be0b-241d72ddc8bf"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello\n",
            "madam\n",
            "!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token = doc[0]\n",
        "print(token.doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jn11ZU3OIE7g",
        "outputId": "fc5e3f67-93a8-45b8-e5c8-5da14240917b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello madam!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"The Brazilian president visited Argentina\")\n",
        "print(doc.ents)\n",
        "print(doc[1].ent_type_, spacy.explain(doc[1].ent_type_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhwJze4oOUSB",
        "outputId": "a8759af5-98f2-4363-ce05-60585f78b65e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Brazilian, Argentina)\n",
            "NORP Nationalities or religious or political groups\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"I visited Buenos Aires when I was on vacation\")\n",
        "print(doc.ents)\n",
        "print(doc[1].ent_type_, spacy.explain(doc[1].ent_type_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXl6RhihOq9c",
        "outputId": "9b94b2c7-1100-4c2b-813b-8f9b88fe33ad"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Buenos Aires,)\n",
            " None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another interesting spaCy features\n",
        "\n",
        "- like_url\n",
        "- like_num\n",
        "- like_emai\n",
        "- token.shape"
      ],
      "metadata": {
        "id": "LOLnqTtBPuRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# token.shape\n",
        "\n",
        "doc = nlp(\"My nickname is Sa123Sous456a\")\n",
        "for token in doc:\n",
        "  print(token.text, token.shape_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnP8WlKzQQ09",
        "outputId": "108e62e0-3d5c-45a7-9af2-cd7be4a0eefd"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My Xx\n",
            "nickname xxxx\n",
            "is xx\n",
            "Sa123Sous456a XxdddXxxxdddx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stop words (such as the, a, an, and, just, with...)\n",
        "\n",
        "doc = nlp(\"She was just walking with a friend to the park, and they had an ice cream along the way.\")\n",
        "for token in doc:\n",
        "  print(token, token.is_stop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5qis9sKQ7We",
        "outputId": "8ae36480-e932-4f56-8be2-5fef37e17a82"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "She True\n",
            "was True\n",
            "just True\n",
            "walking False\n",
            "with True\n",
            "a True\n",
            "friend False\n",
            "to True\n",
            "the True\n",
            "park False\n",
            ", False\n",
            "and True\n",
            "they True\n",
            "had True\n",
            "an True\n",
            "ice False\n",
            "cream False\n",
            "along True\n",
            "the True\n",
            "way False\n",
            ". False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### spaCy's core NLP pipeline notes:\n",
        "- https://spacy.io/usage/processing-pipelines\n",
        "- https://www.bmc.com/blogs/nlu-vs-nlp-natural-language-understanding-processing/\n",
        "\n",
        "Tokenization:\n",
        "- The very first step, breaking raw text into individual units called tokens (words, punctuation, numbers) - Because all the other operations require tokens.\n",
        "- It's the foundational step for all subsequent processing, allowing the NLP model to treat each meaningful unit separately.\n",
        "- How to access: token.text for the token's original string.\n",
        "\n",
        "Lemmatization:\n",
        "- Reducing words to their base or dictionary form, known as a lemma. For example, \"running,\" \"ran,\" and \"runs\" all become \"run.\"\n",
        "- Helps normalize words, so different inflections of the same word are treated consistently, which is crucial for tasks like frequency analysis.\n",
        "- How to access: token.lemma_\n",
        "\n",
        "Part-of-Speech (POS) Tagging\n",
        "- Assigning a grammatical category (e.g., noun, verb, adjective, adverb) to each token.\n",
        "- Provides grammatical context, essential for disambiguating word meanings and understanding syntactic roles.\n",
        "- How to access: token.pos_ (universal tag, like NOUN, VERB) and token.tag_ (detailed tag, language-specific).\n",
        "\n",
        "Dependency Parsing:\n",
        "- Analyzing the grammatical relationships between words in a sentence, creating a dependency tree. It identifies which words modify or depend on others.\n",
        "- Reveals the syntactic structure, allowing for deeper semantic understanding (e.g., identifying subjects, objects, and modifiers).\n",
        "- How to access: token.head (the token this one depends on) and token.dep_ (the type of dependency relationship)."
      ],
      "metadata": {
        "id": "VEPtaP6t5NX5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![spaCy NLP pipeline](https://spacy.io/images/pipeline.svg)"
      ],
      "metadata": {
        "id": "oKqWgpB76O0l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NER — Named Entity Recognition"
      ],
      "metadata": {
        "id": "8ey9vsJb6kQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "text = \"Saulo mora em São Paulo e trabalha na Google desde 2010.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "print(\"NER:\")\n",
        "for ent in doc.ents:\n",
        "    print(f\"Text: {ent.text}, Label: {ent.label_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5INmrXLdSZ0G",
        "outputId": "dddc9a30-d250-4809-e102-ff162e81abc6"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NER:\n",
            "Text: Saulo, Label: PER\n",
            "Text: São Paulo, Label: LOC\n",
            "Text: Google, Label: ORG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Doc\n",
        "- Token\n",
        "- Span\n",
        "- Lexeme"
      ],
      "metadata": {
        "id": "Lnf4nLpG7thb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Doc\n",
        "\n",
        "text = \"Texto de exemplo\"\n",
        "doc = nlp(text) # criando objeto Doc nesse momento\n",
        "print(f\"Tipo do objeto doc: {type(doc)}\")\n",
        "print(f\"Número de tokens no doc: {len(doc)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNj4UuN3TPlZ",
        "outputId": "cc015d31-b57b-4178-a94c-b2f92d015175"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tipo do objeto doc: <class 'spacy.tokens.doc.Doc'>\n",
            "Número de tokens no doc: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Token\n",
        "\n",
        "text = \"Alexa, coloque meu alarme para 6 am\"\n",
        "doc = nlp(text)\n",
        "\n",
        "print(\"\\nDetalhes dos tokens:\")\n",
        "for token in doc:\n",
        "    print(f\"Texto: '{token.text}' | Lema: '{token.lemma_}' | POS: '{token.pos_}' | É alfa: {token.is_alpha}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-Gh_uSLTaXz",
        "outputId": "d4fa4872-534a-4e11-9ddd-007a4462e5e4"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Detalhes dos tokens:\n",
            "Texto: 'Alexa' | Lema: 'alexa' | POS: 'PROPN' | É alfa: True\n",
            "Texto: ',' | Lema: ',' | POS: 'PUNCT' | É alfa: False\n",
            "Texto: 'coloque' | Lema: 'coloque' | POS: 'VERB' | É alfa: True\n",
            "Texto: 'meu' | Lema: 'meu' | POS: 'DET' | É alfa: True\n",
            "Texto: 'alarme' | Lema: 'alarme' | POS: 'NOUN' | É alfa: True\n",
            "Texto: 'para' | Lema: 'para' | POS: 'ADP' | É alfa: True\n",
            "Texto: '6' | Lema: '6' | POS: 'NUM' | É alfa: False\n",
            "Texto: 'am' | Lema: 'am' | POS: 'PROPN' | É alfa: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Span\n",
        "# Span is a piece of Doc\n",
        "# It represents a sequence of one or more adjacent tokens\n",
        "\n",
        "text = \"Eu amo ir ao Rio de Janeiro, é uma cidade linda!\"\n",
        "doc = nlp(text)\n",
        "\n",
        "print(\"\\nSpans:\")\n",
        "for sent in doc.sents:\n",
        "    print(f\"Sentença: '{sent.text}'\")\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(f\"Entidade: '{ent.text}' | Tipo: '{ent.label_}'\")\n",
        "\n",
        "# Manually Span\n",
        "span_manual = doc[3:6]\n",
        "print(f\"Span manual: '{span_manual.text}'\")\n",
        "print(f\"Tipo do span manual: {type(span_manual)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFxsvj_ATvbw",
        "outputId": "c7a3dd21-b5ba-48c2-8dc9-54b9be0f2b07"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Spans (Sentenças e Entidades):\n",
            "Sentença: 'Eu amo ir ao Rio de Janeiro, é uma cidade linda!'\n",
            "Entidade: 'Rio de Janeiro' | Tipo: 'LOC'\n",
            "Span manual: 'ao Rio de'\n",
            "Tipo do span manual: <class 'spacy.tokens.span.Span'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- a Doc is the entire document.\n",
        "- a Doc is composed of a sequence of Tokens.\n",
        "- a Span is a slice of a Doc (a sequence of Tokens).\n",
        "- named entities (ent) are Spans.\n",
        "- each Token refers to a Lexeme in the vocabulary for its context-independent properties."
      ],
      "metadata": {
        "id": "wrCZavUpUhEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter 3: Extracting linguistic features"
      ],
      "metadata": {
        "id": "NHM9ipnmV7O8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### POS tagging\n",
        "One of the core tasks in NLP is Parts of Speech (PoS) tagging, which is giving each word in a text a grammatical category, such as nouns, verbs, adjectives, and adverbs. Through improved comprehension of phrase structure and semantics, this technique makes it possible for machines to study and comprehend human language more accurately."
      ],
      "metadata": {
        "id": "0dzbPcD2WAfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"The quick brown foxes jump over the lazy dogs.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "print(\"POS Tagging example:\")\n",
        "for token in doc:\n",
        "    print(f\"Token: '{token.text}' | Detailed POS Tag (token.tag_): '{token.tag_}' | Universal POS Tag (token.pos_): '{token.pos_}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQTgdpWOXNxO",
        "outputId": "ed097164-2963-46ec-c02f-d603dc8d0300"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POS Tagging example:\n",
            "Token: 'The' | Detailed POS Tag (token.tag_): 'DT' | Universal POS Tag (token.pos_): 'DET'\n",
            "Token: 'quick' | Detailed POS Tag (token.tag_): 'JJ' | Universal POS Tag (token.pos_): 'ADJ'\n",
            "Token: 'brown' | Detailed POS Tag (token.tag_): 'JJ' | Universal POS Tag (token.pos_): 'ADJ'\n",
            "Token: 'foxes' | Detailed POS Tag (token.tag_): 'NNS' | Universal POS Tag (token.pos_): 'NOUN'\n",
            "Token: 'jump' | Detailed POS Tag (token.tag_): 'VBP' | Universal POS Tag (token.pos_): 'VERB'\n",
            "Token: 'over' | Detailed POS Tag (token.tag_): 'IN' | Universal POS Tag (token.pos_): 'ADP'\n",
            "Token: 'the' | Detailed POS Tag (token.tag_): 'DT' | Universal POS Tag (token.pos_): 'DET'\n",
            "Token: 'lazy' | Detailed POS Tag (token.tag_): 'JJ' | Universal POS Tag (token.pos_): 'ADJ'\n",
            "Token: 'dogs' | Detailed POS Tag (token.tag_): 'NNS' | Universal POS Tag (token.pos_): 'NOUN'\n",
            "Token: '.' | Detailed POS Tag (token.tag_): '.' | Universal POS Tag (token.pos_): 'PUNCT'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The more detailed tags (`token.tag_`) come from a tagset called the **Penn Treebank Tagset**, which is very common in NLP for English.\n",
        "\n",
        "* DT: Determiner. Used for articles (a, an, the) and other determiners that precede nouns.\n",
        "  Example: \"The\", \"a\", \"this\".\n",
        "\n",
        "* JJ: Adjective. A word that describes or modifies a noun or pronoun.\n",
        "  Example: \"quick\", \"brown\", \"lazy\".\n",
        "\n",
        "* NNS: Noun, plural. A noun in the plural form.\n",
        "  Example: \"foxes\", \"dogs\", \"cats\".\n",
        "\n",
        "* VBP: Verb, non-3rd person singular present. A verb in the present tense, not in the third person singular.\n",
        "  Example: \"jump\" (I jump, you jump, they jump), \"walk\", \"sing\".\n",
        "\n",
        "* IN: Preposition or subordinating conjunction. A preposition or subordinating conjunction.\n",
        "  Example: \"over\", \"in\", \"on\", \"because\".\n",
        "\n",
        "* . : Punctuation mark, sentence closer. A punctuation mark that ends a sentence.\n",
        "  Example: \".\", \"!\", \"?\".\n",
        "\n",
        "---\n",
        "\n",
        "### Other common tags\n",
        "\n",
        "* NN: Noun, singular or mass. A singular or mass (uncountable) noun.\n",
        "  Example: \"cat\", \"water\", \"love\".\n",
        "\n",
        "* PRP: Personal pronoun. A personal pronoun.\n",
        "  Example: \"I\", \"you\", \"he\", \"she\", \"it\", \"we\", \"they\".\n",
        "\n",
        "* PRP\\$: Possessive pronoun. A possessive pronoun.\n",
        "  Example: \"my\", \"your\", \"his\", \"her\", \"its\", \"our\", \"their\".\n",
        "\n",
        "* VB: Verb, base form. A verb in its base form (infinitive without \"to\").\n",
        "  Example: \"run\", \"walk\", \"sing\".\n",
        "\n",
        "* VBG: Verb, gerund or present participle. A verb in the gerund or present participle form (ending in -ing).\n",
        "  Example: \"running\", \"walking\", \"singing\".\n",
        "\n",
        "* VBN: Verb, past participle. A verb in the past participle form.\n",
        "  Example: \"eaten\", \"walked\", \"sung\".\n",
        "\n",
        "* RB: Adverb. A word that modifies a verb, adjective, or another adverb.\n",
        "  Example: \"quickly\", \"very\", \"happily\".\n",
        "\n",
        "* CC: Coordinating conjunction. A coordinating conjunction (joins words, phrases, or independent clauses).\n",
        "  Example: \"and\", \"but\", \"or\".\n"
      ],
      "metadata": {
        "id": "QiC70PXsXjxi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### WSD — Word Sense Disambiguation\n",
        "- Classical NLU problem\n",
        "- A word can have many sense"
      ],
      "metadata": {
        "id": "zpzCXammZj25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "sent1 = \"I flew to Rome\"\n",
        "sent2 = \"I'm flying to Rome\"\n",
        "sent3 = \"I will fly to Rome\"\n",
        "\n",
        "doc1 = nlp(sent1)\n",
        "doc2 = nlp(sent2)\n",
        "doc3 = nlp(sent3)\n",
        "\n",
        "# Iterates over each document and extracts tokens with POS tag 'VBG' (gerund) or 'VB' (verb in base/infinitive form).\n",
        "# Returns a list of tuples (token text, token lemma).\n",
        "results = []\n",
        "for doc in [doc1, doc2, doc3]:\n",
        "    extracted_tokens = []\n",
        "    for w in doc:\n",
        "        if w.tag_ == 'VBG' or w.tag_ == 'VB':\n",
        "            extracted_tokens.append((w.text, w.lemma_))\n",
        "    results.append(extracted_tokens)\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOcEQtGkb47Z",
        "outputId": "09e25025-2450-4234-f8fa-f7f8285e7800"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[], [('flying', 'fly')], [('fly', 'fly')]]\n"
          ]
        }
      ]
    }
  ]
}